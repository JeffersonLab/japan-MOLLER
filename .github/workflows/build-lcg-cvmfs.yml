---
name: Build LCG on CVMFS

on:
  push:
    branches: [ main ]
  pull_request:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.run_id }}
  cancel-in-progress: true

jobs:
  linux:
    runs-on: ubuntu-24.04
    strategy:
      fail-fast: false
      matrix:
        include:
          # Standard builds without sanitizers
          - release: "LCG_106"
            arch: "x86_64"
            os: "el9"
            compiler: "gcc13"
            opt: "opt"
            cxxflags: "-g -pg"
          - release: "LCG_107"
            arch: "x86_64"
            os: "el9"
            compiler: "clang16"
            opt: "opt"
            cxxflags: ""
          - release: "LCG_107"
            arch: "x86_64"
            os: "el9"
            compiler: "gcc14"
            opt: "opt"
            cxxflags: ""
    env:
      MYSQL_DB: qwparity
      MYSQL_HOST: 127.0.0.1 # avoid localhost since it will use sockets
      MYSQL_PORT: 3306
      MYSQL_USER: qwparity
      MYSQL_PASSWORD: qwparity-${{ github.run_id }}-${{ github.run_attempt }}
      MYSQL_ROOT_PASSWORD: root-${{ github.run_id }}-${{ github.run_attempt }}
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_USER: qwparity
          MYSQL_DATABASE: qwparity
          MYSQL_PASSWORD: qwparity-${{ github.run_id }}-${{ github.run_attempt }}
          MYSQL_ROOT_PASSWORD: root-${{ github.run_id }}-${{ github.run_attempt }}
        ports:
          - 3306:3306
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
    steps:
      - uses: actions/checkout@v5
        with:
          submodules: true
      - uses: cvmfs-contrib/github-action-cvmfs@v5
        with:
          cvmfs_repositories: 'sft.cern.ch,geant4.cern.ch'
      - name: Install ccache
        run: |
          sudo apt-get update
          sudo apt-get install -y ccache
      - name: Setup ccache cache
        uses: actions/cache@v4
        with:
          path: ~/.ccache
          key: ccache-${{ matrix.LCG }}-${{ github.ref_name }}
          restore-keys: |
            ccache-${{ matrix.LCG }}-
            ccache-
      - name: Configure ccache
        run: |
          ccache --set-config=cache_dir=$HOME/.ccache
          ccache --set-config=max_size=1G
          ccache --set-config=compression=true
          ccache --zero-stats
          echo "PATH=/usr/lib/ccache:$PATH" >> $GITHUB_ENV
      - name: Wait for MySQL to be ready
        run: |
          echo "Waiting for MySQL to be ready..."
          echo "MySQL environment variables:"
          echo "MYSQL_HOST: ${{ env.MYSQL_HOST }}"
          echo "MYSQL_PORT: ${{ env.MYSQL_PORT }}"
          echo "MYSQL_USER: ${{ env.MYSQL_USER }}"
          echo "MYSQL_DB: ${{ env.MYSQL_DB }}"
          
          # Check if MySQL port is listening
          echo "Checking if port 3306 is listening..."
          netstat -ln | grep :3306 || echo "Port 3306 not found in netstat"
          
          # Try to connect with timeout
          for i in {30..0}; do
            if mysql -h${{ env.MYSQL_HOST }} -P${{ env.MYSQL_PORT }} -u${{ env.MYSQL_USER }} -p${{ env.MYSQL_PASSWORD }} -e 'SELECT 1' ${{ env.MYSQL_DB }} &> /dev/null; then
              echo "MySQL is ready!"
              break
            fi
            echo "MySQL is unavailable - sleeping (attempt $((31-i))/30)"
            sleep 2
          done
          if [ "$i" = 0 ]; then
            echo "MySQL failed to become ready"
            echo "Trying to connect with more verbose output:"
            mysql -h${{ env.MYSQL_HOST }} -P${{ env.MYSQL_PORT }} -u${{ env.MYSQL_USER }} -p${{ env.MYSQL_PASSWORD }} -e 'SELECT 1' ${{ env.MYSQL_DB }} || true
            exit 1
          fi
      - uses: aidasoft/run-lcg-view@v1
        with:
          release-platform: ${{ matrix.release }}/${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}-${{ matrix.opt }}
          run: |
            echo "::group::Dependencies"
            # Install dependencies
            PYTHONHOME="" PYTHONPATH="" dnf install -y time
            echo "::endgroup::"

            echo "::group::Configuration"
            # Set BOOST_INC_DIR and BOOST_LIB_DIR to point to
            # LCG-provided Boost installation
            LCG_PATH="/cvmfs/sft.cern.ch/lcg/views/${{ matrix.release }}/${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}-${{ matrix.opt }}"
            export BOOST_INC_DIR="${LCG_PATH}/include"
            export BOOST_LIB_DIR="${LCG_PATH}/lib"

            # Generate setup scripts
            chmod +x SetupFiles/make_SET_ME_UP
            SetupFiles/make_SET_ME_UP
            echo "::endgroup::"

            echo "::group::Compilation of dependencies with ccache"
            # Build the dependencies
            # Note that postgresql fails in v0.65; see rbock/sqlpp11#623
            cmake -Bthirdparty/sqlpp11-build -Sthirdparty/sqlpp11/ \
              -DBUILD_MARIADB_CONNECTOR=ON \
              -DBUILD_MYSQL_CONNECTOR=ON \
              -DBUILD_POSTGRESQL_CONNECTOR=OFF \
              -DBUILD_SQLITE3_CONNECTOR=ON \
              -DCMAKE_INSTALL_PREFIX=thirdparty/sqlpp11-install \
              -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER_LAUNCHER=ccache
            cmake --build thirdparty/sqlpp11-build -j$(nproc) --target install
            export CMAKE_PREFIX_PATH=${CMAKE_PREFIX_PATH}:$PWD/thirdparty/sqlpp11-install
            echo "::endgroup::"

            echo "::group::Compilation of main project with ccache"
            # Build the project
            cmake -Bbuild -S. -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_FLAGS="${{ matrix.cxxflags }}"
            cmake --build build -j$(nproc)
            echo "::endgroup::"
            
            echo "::group::ccache statistics"
            ccache --show-stats
            echo "::endgroup::"

            echo "::group::Mock data generation"
            # Run the mock data generator and analysis as described in README
            source SetupFiles/SET_ME_UP.bash
            
            # Generate mock data
            /usr/bin/time -v \
            build/qwmockdatagenerator -r 4 -e 1:20000 \
              --config qwparity_simple.conf \
              --detectors mock_newdets.map \
              --data .
            echo "::endgroup::"

            echo "::group::Create database (sqlite3)"
            # Create and populate the database
            # (sqlite3 only supports AUTOINCREMENT on INTEGER keys)
            # (sqlite3 does not support ENUM, so convert to TEXT with CHECK)
            sed 's/AUTO_INCREMENT//g;s/\(\S*\)\sENUM(\([^)]*\))/\1 TEXT CHECK(\1 in (\2))/g' Parity/prminput/qwparity_schema.sql | sqlite3 qwparity.db

            echo "::group::Mock data analysis (sqlite3)"
            # Analyze the generated mock data
            /usr/bin/time -v \
            build/qwparity -r 4 \
              --config qwparity_simple.conf \
              --detectors mock_newdets.map \
              --datahandlers mock_datahandlers.map \
              --data . \
              --rootfiles . \
              --write-promptsummary \
              --QwDatabase.accesslevel RW \
              --QwDatabase.dbtype sqlite3 \
              --QwDatabase.dbname qwparity.db
            echo "::endgroup::"

            echo "::group::Print database contents (sqlite3)"
            # Print the database contents
            sqlite3 qwparity.db .dump | tee qwparity-sqlite3.sql
            echo "::endgroup::"

            echo "::group::Create database (mysql)"
            # Test MySQL connection first
            echo "Testing MySQL connection..."
            mysql -h${{ env.MYSQL_HOST }} -P${{ env.MYSQL_PORT }} -u${{ env.MYSQL_USER }} -p${{ env.MYSQL_PASSWORD }} -e "SELECT VERSION();" ${{ env.MYSQL_DB }}
            
            # Create and populate the database
            echo "Creating database schema..."
            cat Parity/prminput/qwparity_schema.sql | mysql \
              -h${{ env.MYSQL_HOST }} \
              -P${{ env.MYSQL_PORT }} \
              -u${{ env.MYSQL_USER }} \
              -p${{ env.MYSQL_PASSWORD }} \
              ${{ env.MYSQL_DB }}
            echo "::endgroup::"

            echo "::group::Print database contents (mysql)"
            # Print the database contents
            echo "Showing MySQL tables..."
            mysql \
              -h${{ env.MYSQL_HOST }} \
              -P${{ env.MYSQL_PORT }} \
              -u${{ env.MYSQL_USER }} \
              -p${{ env.MYSQL_PASSWORD }} \
              ${{ env.MYSQL_DB }} -e "SHOW TABLES;" | tee qwparity-mysql.sql
            echo "::endgroup::"

            echo "::group::Mock data analysis (mysql)"
            # Analyze the generated mock data
            build/qwparity -r 4 \
              --config qwparity_simple.conf \
              --detectors mock_newdets.map \
              --datahandlers mock_datahandlers.map \
              --data . \
              --rootfiles . \
              --write-promptsummary \
              --QwDatabase.accesslevel RW \
              --QwDatabase.dbtype mysql \
              --QwDatabase.dbname ${{ env.MYSQL_DB }} \
              --QwDatabase.host ${{ env.MYSQL_HOST }} \
              --QwDatabase.port ${{ env.MYSQL_PORT }} \
              --QwDatabase.user ${{ env.MYSQL_USER }} \
              --QwDatabase.password ${{ env.MYSQL_PASSWORD }}
            echo "::endgroup::"

            echo "::group:: Profile analysis"
            if [ -f gmon.out ] ; then
              gprof build/qwparity | tee qwparity.txt
            fi
            echo "::endgroup::"

      - name: Compress build directory
        run: tar -caf build.tar.zst build/
      - name: Upload build artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: build.tar.zst
          retention-days: 7
          if-no-files-found: error

      - name: Upload profiling analysis
        uses: actions/upload-artifact@v4
        with:
          name: gprof-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: |
            qwparity.txt
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload prompt summary
        uses: actions/upload-artifact@v4
        with:
          name: prompt-summary-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: |
            summary_*.txt
          retention-days: 7
          if-no-files-found: error

      - name: Upload database dumps
        uses: actions/upload-artifact@v4
        with:
          name: qwparity-sql-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: |
            qwparity-*.sql
          retention-days: 7
          if-no-files-found: error

      - name: Upload regression alias definitions
        uses: actions/upload-artifact@v4
        with:
          name: regalias-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: |
            *regalias*.C
          retention-days: 7
          if-no-files-found: error

      - name: Download target branch artifacts (prompt summary)
        if: github.event_name == 'pull_request'
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: build-lcg-cvmfs.yml
          branch: ${{ github.event.pull_request.base.ref }}
          name: prompt-summary-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: ./target
          if_no_artifact_found: warn

      - name: Download target branch artifacts (regalias)
        if: github.event_name == 'pull_request'
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: build-lcg-cvmfs.yml
          branch: ${{ github.event.pull_request.base.ref }}
          name: regalias-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: ./target
          if_no_artifact_found: warn

      - name: Compare artifacts
        if: github.event_name == 'pull_request'
        run: |
          echo "Comparing artifacts for ${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}"

          # Check if target artifacts exist
          if [ ! -d "./target" ] || [ -z "$(ls -A ./target)" ]; then
            echo "⚠️  No target branch artifacts found. This may be the first run or target branch hasn't been built recently."
            echo "Skipping comparison for this configuration."
            exit 0
          fi

          # Find summary files in both directories
          current_files=$(find ./ -maxdepth 1 -name "summary_*.txt" -o -name "*regalias*.C" | sort)
          target_files=$(find ./target -name "summary_*.txt" -o -name "*regalias*.C" | sort)

          echo "Current files found:"
          echo "$current_files"
          echo "Target files found:"
          echo "$target_files"

          # Compare each file
          comparison_failed=false
          for current_file in $current_files; do
            filename=$(basename "$current_file")
            target_file="./target/$filename"

            if [ ! -f "$target_file" ]; then
              echo "❌ Target file $filename not found"
              comparison_failed=true
              continue
            fi

            echo "Comparing $filename..."

            # Skip lines containing timestamps and metadata that can vary
            if diff -q <(grep -v "Start Time:\|End Time:" "$current_file") <(grep -v "Start Time:\|End Time:" "$target_file") > /dev/null; then
              echo "✅ $filename: No meaningful differences found"
            else
              echo "❌ $filename: Differences found beyond timestamps"
              echo "--- Expected (target branch) ---"
              grep -v "Start Time:\|End Time:" "$target_file" | head -20
              echo "--- Actual (current PR) ---"
              grep -v "Start Time:\|End Time:" "$current_file" | head -20
              echo "--- Detailed diff ---"
              diff -u <(grep -v "Start Time:\|End Time:" "$target_file") <(grep -v "Start Time:\|End Time:" "$current_file") | head -50
              comparison_failed=true
            fi
          done

          if [ "$comparison_failed" = "true" ]; then
            echo "❌ Artifact comparison failed. Changes detected in artifacts beyond timestamps."
            exit 1
          else
            echo "✅ All artifacts match expected results (ignoring timestamps)."
          fi


  valgrind:
    runs-on: ubuntu-latest
    needs: linux
    if: github.event_name == 'pull_request'
    strategy:
      fail-fast: false
      matrix:
        include:
          - release: "LCG_107"
            arch: "x86_64"
            os: "el9"
            compiler: "gcc14"
            opt: "opt"
            cxxflags: ""
    steps:
      - uses: actions/checkout@v3

      - name: Download build artifact
        uses: actions/download-artifact@v4
        with:
          name: build-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: .
      - name: Uncompress build artifact
        run: tar -xaf build.tar.zst

      - uses: cvmfs-contrib/github-action-cvmfs@v3
        with:
          cvmfs_repositories: 'sft.cern.ch,geant4.cern.ch'
      - uses: aidasoft/run-lcg-view@v1
        with:
          release-platform: ${{ matrix.release }}/${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}-${{ matrix.opt }}
          run: |
            echo "::group::Mock data generation"
            build/qwmockdatagenerator -r 4 -e 1:20000 --config qwparity_simple.conf --detectors mock_newdets.map --data .
            echo "::endgroup::"

            echo "::group::Run callgrind on mock data analysis (no rntuples, no trees, no hists)"
            valgrind --tool=callgrind --callgrind-out-file=callgrind.out.no-out --instr-atstart=no \
              build/qwparity -r 4 --config qwparity_simple.conf --detectors mock_newdets.map --datahandlers mock_datahandlers.map --data . --rootfiles . --write-promptsummary --callgrind-instr-start-event-loop \
                --disable-trees --disable-hists
            echo "::endgroup::"

            echo "::group::Annotate callgrind info on source code (no rntuples, no trees, no hists)"
            callgrind_annotate \
              -I=Parity/src/ -I=Parity/include -I=Analysis/src -I=Analysis/include \
              callgrind.out.no-out Parity/main/QwParity.cc | tee -a callgrind-no-out.txt
            echo "::endgroup::"

            echo "::group::Run callgrind on mock data analysis (trees, hists)"
            valgrind --tool=callgrind --callgrind-out-file=callgrind.out.trees --instr-atstart=no \
              build/qwparity -r 4 --config qwparity_simple.conf --detectors mock_newdets.map --datahandlers mock_datahandlers.map --data . --rootfiles . --write-promptsummary --callgrind-instr-start-event-loop
            echo "::endgroup::"

            echo "::group::Annotate callgrind info on source code (trees, hists)"
            callgrind_annotate \
              -I=Parity/src/ -I=Parity/include -I=Analysis/src -I=Analysis/include \
              callgrind.out.trees Parity/main/QwParity.cc | tee -a callgrind-trees.txt
            echo "::endgroup::"

            echo "::group::Run callgrind on mock data analysis (rntuples, hists)"
            valgrind --tool=callgrind --callgrind-out-file=callgrind.out.rntuples --instr-atstart=no \
              build/qwparity -r 4 --config qwparity_simple.conf --detectors mock_newdets.map --datahandlers mock_datahandlers.map --data . --rootfiles . --write-promptsummary --callgrind-instr-start-event-loop \
                --enable-rntuples --disable-trees
            echo "::endgroup::"

            echo "::group::Annotate callgrind info on source code (rntuples, hists)"
            callgrind_annotate \
              -I=Parity/src/ -I=Parity/include -I=Analysis/src -I=Analysis/include \
              callgrind.out.rntuples Parity/main/QwParity.cc | tee -a callgrind-rntuples.txt
            echo "::endgroup::"

      - name: Upload callgrind analysis
        uses: actions/upload-artifact@v4
        with:
          name: callgrind-${{ matrix.release }}-${{ matrix.arch }}-${{ matrix.os }}-${{ matrix.compiler }}
          path: |
            callgrind*.txt
          retention-days: 7
          if-no-files-found: error
